# -*- coding: utf-8 -*-
"""Diabetes Predict Analysis
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1pb-ugxcdSslfcK6tBLmSDZm8ZuEp1OzF

# **Librarys**
"""

from pprint import pprint
import pandas as pd
import numpy as np

#Statistic
from scipy import stats

#Visualization
import plotly.graph_objects as go
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.cluster import KMeans

df = pd.read_csv("C:/Users/DELL/Downloads/DataSets/diabetes_prediction_dataset.csv")

"""# **DataFrame observation**
Supervised [Classification / Regression] (or) Unsupervised [Clustering / Association]
Dependent column
Independent column
Continuous column
Category column
"""

len(df.blood_glucose_level.unique())

# Dependent -
# Independent -

continuous_columns = ["bmi"]
category_columns = ["gender",	"age",	"hypertension", "heart_disease", "smoking_history",
                    "HbA1c_level","blood_glucose_level","diabetes"]

#Unsupervised

"""# **Data cleaning using pandas**
Handling Null Values
Handling Duplicates
Data Type Conversion
Standardizing or Normalizing Data
Handling Text Data
Handling Date and Time Data
Handling Outliers
"""

df.info()

df.describe()

df.isnull().sum()

"""# **Hypothesis testing / Statistical analysis**
Continuous - Central Limit Theorem, 1-Tailed Test (one-sample t-test)
Continuous vs. Continuous - Correlation, 2-Tailed Test (two-sample t-test)
Continuous vs. Categorical - ANOVA (Analysis of Variance)
Categorical vs. Categorical - Chi-Square Test
"""

def hypothesisTesting(continuous_columns = [], category_columns = [], sampling_rate = 0.20, sampling_frac=0.05):
  #Central Limit Theorem
  oneContinesColumn_result = {}
  hypothesis_df = pd.DataFrame(columns=df.columns, index=df.columns)
  if continuous_columns:
    samplesize = int(sampling_rate * len(df[continuous_columns[0]]))
    for column in continuous_columns:
      population=df[column].values
      population_mean = population.mean()
      sample_mean=[]
      for i in range(40):
        sample=np.random.choice(population,samplesize)
        sample_mean.append(sample.mean())
      oneContinesColumn_result[column] = {
                                          "Population Mean": population_mean,
                                          "Sample Means": {np.mean(sample_mean)}
                                          }

  #1-Tailed Test
  if continuous_columns:
    samplesize = int(sampling_rate * len(df[continuous_columns[0]]))
    for column in continuous_columns:
      H0_accepted = 0
      H0_rejected = 0
      for i in range(samplesize):
        sample=df[column].sample(frac=sampling_frac)
        t_test,p_value=stats.ttest_1samp(sample,df[column].mean())
        if p_value > 0.5:
          H0_accepted += 1
        else:
          H0_rejected += 1

      if H0_accepted > H0_rejected:
        oneContinesColumn_result[column].update( {
                                            "H0_accepted": H0_accepted,
                                            "H0_rejected": H0_rejected,
                                            "Conclusion": "H0 is accepted, Ha is rejected, There is no significant effect"
                                          } )
      else:
          oneContinesColumn_result[column].update( {
                                              "H0_accepted": H0_accepted,
                                              "H0_rejected": H0_rejected,
                                              "Conclusion": "H0 is rejected, Ha is accepted, There is a significant effect"
                                              } )

  #2-Tailed Test
  for i in range(len(continuous_columns) - 1):
      column_1 = continuous_columns[i]
      for column_2 in continuous_columns[i+1:]:
        H0_accepted = 0
        H0_rejected = 0
        for i in range(20):
          sample1 = df[column_1].sample(frac=sampling_frac)
          sample2 = df[column_2].sample(frac=sampling_frac)
          t_test, p_value = stats.ttest_ind(sample1, sample2)
          if p_value > 0.5:
            H0_accepted += 1
          else:
            H0_rejected += 1

        if H0_accepted > H0_rejected:
          #H0 is accepted, Ha is rejected, There is no significant effect. "H0_accepted": H0_accepted, "H0_rejected": H0_rejected
          hypothesis_df[column_1][column_2] = "H0 is accepted"
          hypothesis_df[column_2][column_1] = "H0 is accepted"
        else:
          #H0 is rejected, Ha is accepted, There is a significant effect. "H0_accepted": H0_accepted, "H0_rejected": H0_rejected
            hypothesis_df[column_1][column_2] = "H0 is rejected"
            hypothesis_df[column_2][column_1] = "H0 is rejected"

  #Chi-Square Test
  if category_columns:
    for i in range(len(category_columns) - 1):
        column_1 = category_columns[i]
        for column_2 in category_columns[i + 1:]:
            data = pd.crosstab(df[column_1], df[column_2])
            observed_values = data.values
            chi2_stat, p_value, _, _ = stats.chi2_contingency(observed_values)

            if p_value > 0.05:
                # H0 is accepted, There is no relationship between two columns we're comparing
                hypothesis_df[column_1][column_2] = "H0 is accepted"
                hypothesis_df[column_2][column_1] = "H0 is accepted"
            else:
                # H0 is rejected, There is a relationship between two columns we're comparing
                hypothesis_df[column_1][column_2] = "H0 is rejected"
                hypothesis_df[column_2][column_1] = "H0 is rejected"

  #ANOVA
  if continuous_columns and category_columns:
    for category_column in category_columns:
      for continuous_column in continuous_columns:
        group = df[category_column].unique()
        data = {}
        for i in group:
          data[i]=df[continuous_column][df[category_column]==i]

        f_value, p_value = stats.f_oneway(*[data[i] for i in group])
        if p_value > 0.05:
            # H0 is accepted, There is no relationship between two columns we're comparing
            hypothesis_df[category_column][continuous_column] = "H0 is accepted"
            hypothesis_df[continuous_column][category_column] = "H0 is accepted"
        else:
            # H0 is rejected, There is a relationship between two columns we're comparing
            hypothesis_df[category_column][continuous_column] = "H0 is rejected"
            hypothesis_df[continuous_column][category_column] = "H0 is rejected"

  return oneContinesColumn_result, hypothesis_df

"""# Correlation"""

df.corr()

"""# **Result Hypothesis**"""

ContinesColumn_result, comperativeColumn_result = hypothesisTesting(continuous_columns , category_columns)

ContinesColumn_result_df = pd.DataFrame(ContinesColumn_result)
ContinesColumn_result_df

# Create a heatmap
sns.heatmap(comperativeColumn_result == 'H0 is rejected', annot=True, cmap='coolwarm')
plt.title('Hypothesis Test Results')
plt.show()

sns.set()
comperativeColumn_result.fillna(3, inplace = True)
comperativeColumn_result.replace({'H0 is accepted': 1, 'H0 is rejected': 0}, inplace=True)
fig = px.imshow(comperativeColumn_result, color_continuous_scale='Viridis',
                title="Correlation Matrix")
fig.show()

correlation_matrix = df.corr()
fig = px.imshow(correlation_matrix, color_continuous_scale='Viridis',
                title="Correlation Matrix")
fig.show()

"""# **Data Visualization**"""

df.head(10)

plt.figure(figsize=(8, 6))  # Adjust size if needed
df.boxplot(column='blood_glucose_level', by='diabetes')
plt.xlabel('diabetes')
plt.ylabel('blood_glucose_level')
plt.title('Box plot of blood glucose level by diabetes')
plt.grid(True)
plt.show()

columns = ['hypertension', 'HbA1c_level', 'heart_disease', 'blood_glucose_level']
fig, axs = plt.subplots(2, 2, figsize=(5, 4))  # 2x2 grid of subplots
for i, column in enumerate(columns):
    row = i // 2
    col = i % 2
    df.boxplot(column=column, by='diabetes', ax=axs[row, col])
    axs[row, col].set_title(f'{column.replace("_", " ").capitalize()} by Diabetes')
    axs[row, col].set_xlabel('Diabetes')
    axs[row, col].set_ylabel(column.replace('_', ' ').capitalize())
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
df.boxplot(column='bmi', by='diabetes')
plt.xlabel('diabetes')
plt.ylabel('bmi')
plt.title('Box plot of bmi by diabetes')
plt.grid(True)
plt.show()

"""# **Preprocessing**"""

# Replacing categorical values with numerical equivalents
from sklearn.preprocessing import OrdinalEncoder
encode = OrdinalEncoder()
df['gender'] = encode.fit_transform(df[['gender']])
df['smoking_history'] = encode.fit_transform(df[['smoking_history']])

"""# **Machine Learning**"""

# 1 data availability
# 2 separating independent and dependent
# 3 identifying algorithms/Model
# 4 training
# 5 evaluation

from sklearn.model_selection import train_test_split
x=df.drop("diabetes",axis=1)
y=df["diabetes"]
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)

from sklearn.metrics import confusion_matrix,accuracy_score

class Classification_models:
  def __init__(self,x_train,x_test,y_train,y_test):
    self.x_train = x_train
    self.x_test = x_test
    self.y_train = y_train
    self.y_test = y_test

  def decisiontree(self):
    from sklearn.tree import DecisionTreeClassifier
    model = DecisionTreeClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print('Decision Tree Classifier accuracy score: ',accuracy)
    return accuracy

  def RandomForestClassifier(self):
    from sklearn.ensemble import RandomForestClassifier
    model = RandomForestClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print('Random Forest Classifier accuracy score: ',accuracy)
    return accuracy

  def Logistic(self):
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print('Random Forest Classifier accuracy score: ',accuracy)
    return accuracy

  def SupertVector(self):
    from sklearn import svm
    model = svm.SVC().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print('Support vector machines accuracy score: ',accuracy)
    return accuracy

  def KNeighborsClassifier(self):
    from sklearn.neighbors import KNeighborsClassifier
    model = KNeighborsClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print('KNeighbors Classifier accuracy score: ',accuracy)
    return accuracy

  def GaussianNaiveBayes(self):
    from sklearn.naive_bayes import GaussianNB
    model=GaussianNB().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print("Naive Bayes Classifier accuracy score: ",accuracy)
    return accuracy

  def GradientBoosting(self):
    from sklearn.ensemble import GradientBoostingClassifier
    model = GradientBoostingClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy  = accuracy_score(y_test,y_pred)
    print("Gradient Boosting Classifier accuracy score: ",accuracy)
    return accuracy

  def AdaBoost(self):
    from sklearn.ensemble import AdaBoostClassifier
    model = AdaBoostClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print("AdaBoost Classifier accuracy score: ",accuracy)
    return accuracy

  def SGDClassifier(self):
    from sklearn.linear_model import SGDClassifier
    model = SGDClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print("SGD Classifier accuracy score: ",accuracy)
    return accuracy

  def MLPClassifier(self):
    from sklearn.neural_network import MLPClassifier
    model = MLPClassifier().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print("Neural network models accuracy score: ",accuracy)
    return accuracy

  def NearestCentroid(self):
    from sklearn.neighbors import NearestCentroid
    model = NearestCentroid().fit(x_train,y_train)
    y_pred = model.predict(x_test)
    accuracy = accuracy_score(y_test,y_pred)
    print("Nearest Neighbors accuracy score: ",accuracy)
    return accuracy

model = Classification_models(x_train,x_test,y_train,y_test)
accuracy_scores = {
    'DecisionTree': model.decisiontree(),
    'RandomForest': model.RandomForestClassifier(),
    'SupertVector': model.SupertVector(),
    'KNeighborsClassifier' : model.KNeighborsClassifier(),
    'GaussianNaiveBayes' : model.GaussianNaiveBayes(),
    'GradientBoosting' : model.GradientBoosting(),
    'AdaBoost' : model.AdaBoost(),
    'SGDClassifier' : model.SGDClassifier(),
    'MLPClassifier' : model.MLPClassifier(),
    'NearestCentroid' : model.NearestCentroid(),
    'Logistic' : model.Logistic()}

max_score_classifier = max(accuracy_scores, key=accuracy_scores.get)
max_accuracy_score = accuracy_scores[max_score_classifier]

print(f"\nMaximum accuracy score: {max_accuracy_score:.4f} achieved by {max_score_classifier} classifier.\n")

"""# **Evaluation**"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import confusion_matrix,accuracy_score

model = GradientBoostingClassifier().fit(x_train,y_train)
y_pred = model.predict(x_test)
accuracy  = accuracy_score(y_test,y_pred)
print("Gradient Boosting Classifier accuracy score: ",accuracy)

confusion=confusion_matrix(y_test,y_pred)
confusion

# Streamlit part----

import streamlit as st
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.preprocessing import OrdinalEncoder
from sklearn.model_selection import train_test_split

st.set_page_config(layout="wide")
# Load the dataset
df = pd.read_csv("C:/Users/DELL/Downloads/DataSets/diabetes_prediction_dataset.csv")

# Preprocessing
df.gender = df.gender.replace({'Female':0,'Male':1,'Other':2})
df.smoking_history = df.smoking_history.replace({'never':0, 'No Info':1, 'current':2 ,'former':3, 'ever':4, 'not current':5})

# Train-test split
x = df.drop("diabetes", axis=1)
y = df["diabetes"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)

# Train the model
model = GradientBoostingClassifier().fit(x_train, y_train)

#st.title(' :black[Diabetes Checking App]')
st.markdown(
    "<h1 style='text-align: center; color: blue;'>&#x1F489 Diabetes Prediction Web App </h1>",
    unsafe_allow_html=True)
st.header(' :black[Fill the below details to find diabetes]')


st.markdown(f""" <style>.stApp {{
                    background: url('https://t3.ftcdn.net/jpg/02/39/68/72/240_F_239687219_PLbiqAuTtNEneUlAZscznUPwXmS7BqxR.jpg');   
                    background-size: cover}}
                 </style> """,unsafe_allow_html=True)

col1,col2= st.columns(2)

# Create an empty DataFrame to store user inputs
user_data = pd.DataFrame(columns=['gender', 'age', 'hypertension', 'heart_disease', 'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level'])
with col1:
    sub_col1, sub_col2 = st.columns(2)
    with sub_col1:
        gender = st.selectbox('Select Gender', ('Male', 'Female'))
        age = st.number_input('Select Age', min_value=0, max_value=150, value=25)  # Number input
        hypertension = st.selectbox('You have Hypertension?', ('Yes', 'No'))
        heart_disease = st.selectbox('You have Heart Disease?', ('Yes', 'No'))
    with sub_col2:
        bmi = st.number_input('Select Your BMI value', min_value=10.0, max_value=70.0, value=25.0, step=0.1)  # BMI range
        HBA1c_Level = st.number_input('Select HBA1C Level',min_value=0.0, max_value=20.0, value=5.0, step=0.1)  # HbA1c level range
        blood_glucose_level = st.number_input('Select Blood glucose Level', min_value=0.0, max_value=500.0, value=100.0, step=1.0)  # Blood glucose level range
        smoking_history = st.selectbox('Select Your Smoking History', ('Never Smoked', 'No info', 'Currently Smoke','Ever Smoked', 'Not currently'))

# Map smoking history to numerical value using a dictionary
smoking_mapping = {'never':0, 'No Info':1, 'current':2 ,'former':3, 'ever':4, 'not current':5}
smoking_val = smoking_mapping.get(smoking_history)

# Convert categorical variables to numerical values
gender_val = 0 if gender == 'Female' else 1
hypertension_val = 1 if hypertension == 'Yes' else 0
heart_disease_val = 1 if heart_disease == 'Yes' else 0

# Insert user input into DataFrame at index 0
user_data.loc[0] = [gender_val, age, hypertension_val, heart_disease_val, smoking_val,
                    bmi, HBA1c_Level, blood_glucose_level]

# Predict
if st.button('Check Diabetes'):
    # Make prediction
    prediction = model.predict(user_data)[0]
    if prediction == 1:
        st.success('You have diabetes.')
        st.write('''Suggestions:
                    1.Control your diet by limiting sugar and carbohydrates,
                    2.Exercise regularly to manage blood sugar levels,
                    3.Monitor blood sugar levels consistently and take prescribed medication.''')
    else:
        st.success('You do not have diabetes.')
        

